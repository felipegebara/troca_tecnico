{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libs usadas no code\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from functools import reduce\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split  # Import train_test_split function\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transaformacap da coluna date em datetime\n",
    "\n",
    "\n",
    "time_col = ['date']\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('C:/Users/fgeba/Downloads/SCORE/soccer-spi/tecnicos_br_modelagem.csv', sep=\";\", parse_dates=time_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                  int64\n",
       "date           datetime64[ns]\n",
       "league_id               int64\n",
       "league                 object\n",
       "team1                  object\n",
       "team2                  object\n",
       "proj_score1           float64\n",
       "proj_score2           float64\n",
       "score1                  int64\n",
       "score2                  int64\n",
       "tecnico                object\n",
       "saiu                    int64\n",
       "home                    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criacao de duas variaves utilizadas no codigo \n",
    "\n",
    "\n",
    "data['ponto']=np.where(data['score1']>data['score2'],3,np.where(data['score1']==data['score2'],1,0))\n",
    "data['ponto']=np.where(data['home']==1,data['ponto'],np.where(data['score1']>data['score2'],0,np.where(data['score1']==data['score2'],1,3)))                       \n",
    "\n",
    "data['saldo_gol']=np.where(data['home']==1,data['score1']-data['score2'],data['score1']-data['score2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criacao do lag das variaveis\n",
    "data['ponto_l1'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['ponto'].shift(1))\n",
    "data['ponto_l2'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['ponto'].shift(2))\n",
    "data['ponto_l3'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['ponto'].shift(3))\n",
    "data['ponto_l4'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['ponto'].shift(4))\n",
    "data['ponto_l5'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['ponto'].shift(5))\n",
    "\n",
    "data['saldo_gol_l1'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['saldo_gol'].shift(1))\n",
    "data['saldo_gol_l2'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['saldo_gol'].shift(2))\n",
    "data['saldo_gol_l3'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['saldo_gol'].shift(3))\n",
    "data['saldo_gol_l4'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['saldo_gol'].shift(4))\n",
    "data['saldo_gol_l5'] = (data.sort_values(by=['date'], ascending=True).groupby(['tecnico'])['saldo_gol'].shift(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcoes que utilizei a seguir de maximo e soma \n",
    "def soma5(v1, v2, v3,v4,v5):\n",
    "    y = np.array([v1, v2, v3,v4,v5])\n",
    "    return np.nansum(y)\n",
    "\n",
    "def max5(v1, v2, v3,v4,v5):\n",
    "    y = np.array([v1, v2, v3,v4,v5])\n",
    "    return np.nanmax(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fgeba\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: All-NaN slice encountered\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data['pontos_5jogos'] = data.apply(lambda row: soma5(row['ponto_l1'], row['ponto_l2'],row['ponto_l3'],row['ponto_l4'],row['ponto_l5']), axis=1)\n",
    "data['pontos_4jogos'] = data.apply(lambda row: soma5(row['ponto_l1'], row['ponto_l2'],row['ponto_l3'],row['ponto_l4'],np.nan), axis=1)\n",
    "data['pontos_3jogos'] = data.apply(lambda row: soma5(row['ponto_l1'], row['ponto_l2'],row['ponto_l3'],np.nan,np.nan), axis=1)\n",
    "data['pontos_2jogos'] = data.apply(lambda row: soma5(row['ponto_l1'], row['ponto_l2'],np.nan,np.nan,np.nan), axis=1)\n",
    "data['pontos_1jogos'] = data.apply(lambda row: soma5(row['ponto_l1'], np.nan,np.nan,np.nan,np.nan), axis=1)\n",
    "\n",
    "data['max_saldo_5games'] = data.apply(lambda row: max5(row['saldo_gol_l1'], row['saldo_gol_l2'],row['saldo_gol_l3'],row['saldo_gol_l4'],row['saldo_gol_l5']), axis=1)\n",
    "data['max_saldo_4games'] = data.apply(lambda row: max5(row['saldo_gol_l1'], row['saldo_gol_l2'],row['saldo_gol_l3'],row['saldo_gol_l4'],np.nan), axis=1)\n",
    "data['max_saldo_3games'] = data.apply(lambda row: max5(row['saldo_gol_l1'], row['saldo_gol_l2'],row['saldo_gol_l3'],np.nan,np.nan), axis=1)\n",
    "data['max_saldo_2games'] = data.apply(lambda row: max5(row['saldo_gol_l1'], row['saldo_gol_l2'],np.nan,np.nan,np.nan), axis=1)\n",
    "data['max_saldo_1games'] = data.apply(lambda row: max5(row['saldo_gol_l1'], np.nan,np.nan,np.nan,np.nan), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base de validacao \n",
    "\n",
    "data=data[data['ponto_l1']>=0]\n",
    "\n",
    "d3_ott=data[data['date']>='2020-12-01']\n",
    "\n",
    "data=data[data['date']<'2020-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_cols = [\n",
    "    'pontos_5jogos',\n",
    "    'pontos_4jogos',\n",
    "    'pontos_3jogos',\n",
    "    'pontos_2jogos',\n",
    "    'pontos_1jogos',\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "data=data[data['ponto_l1']>=0]\n",
    "data['saiu'] = data['saiu'].astype(int)\n",
    "    \n",
    "X=data[feature_cols]\n",
    "\n",
    "y=data['saiu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fgeba\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:540: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\fgeba\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf2=RandomForestClassifier(n_estimators=10, random_state=0,max_depth=4, oob_score  =  True )\n",
    "\n",
    "clf2.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58 19]\n",
      " [ 8 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81        77\n",
      "           1       0.79      0.90      0.84        78\n",
      "\n",
      "    accuracy                           0.83       155\n",
      "   macro avg       0.83      0.83      0.82       155\n",
      "weighted avg       0.83      0.83      0.82       155\n",
      "\n",
      "0.8258064516129032\n",
      "R^2 Training Score: 0.87 \n",
      "OOB Score: 0.84 \n",
      "R^2 Validation Score: 0.83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pontos_4jogos</th>\n",
       "      <td>0.358291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pontos_1jogos</th>\n",
       "      <td>0.312106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pontos_3jogos</th>\n",
       "      <td>0.144057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pontos_5jogos</th>\n",
       "      <td>0.098879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pontos_2jogos</th>\n",
       "      <td>0.086667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance\n",
       "pontos_4jogos    0.358291\n",
       "pontos_1jogos    0.312106\n",
       "pontos_3jogos    0.144057\n",
       "pontos_5jogos    0.098879\n",
       "pontos_2jogos    0.086667"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(clf2.score(X_train, y_train), \n",
    "                                                                                             clf2.oob_score_,\n",
    "                                                                                             clf2.score(X_test, y_test)))\n",
    "\n",
    "feature_importances = pd.DataFrame(clf2.feature_importances_, index = X.columns,  columns=['importance']).sort_values('importance',  ascending=False)\n",
    "feature_importances[0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "Xc=data[feature_cols]\n",
    "\n",
    "yc=data['saiu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=clf2.predict_proba(Xc)\n",
    "df = pd.DataFrame(y_pred,columns=['good','bad'])\n",
    "df2=df.reset_index(drop=True).merge(yc.reset_index(drop=True), left_index=True, right_index=True)\n",
    "df2.to_csv(\"C:/Users/fgeba/Downloads/saida.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "Xc=d3_ott[feature_cols]\n",
    "\n",
    "yc=d3_ott['saiu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_ott.to_csv(\"C:/Users/fgeba/Downloads/saida.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=clf2.predict_proba(Xc)\n",
    "df = pd.DataFrame(y_pred,columns=['good','bad'])\n",
    "df2=df.reset_index(drop=True).merge(d3_ott.reset_index(drop=True), left_index=True, right_index=True)\n",
    "df2.to_csv(\"C:/Users/fgeba/Downloads/saida2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
